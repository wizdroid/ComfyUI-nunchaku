{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ComfyUI on Colab"
      ],
      "metadata": {
        "id": "jvVAfKCBPzsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if GPU exists"
      ],
      "metadata": {
        "id": "D6q5K_0cQA0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected! Go to Runtime > Change runtime type > GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neOMG6iCQDjx",
        "outputId": "d0381753-efc3-4ff0-89f3-674051cb2e37"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA L4\n",
            "CUDA version: 12.6\n",
            "GPU Memory: 22.16 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Dependancies"
      ],
      "metadata": {
        "id": "pgjvE8DbQSjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -qq aria2 wget git -y\n",
        "print(\"âœ… System dependencies installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEqpAjI6QYFj",
        "outputId": "ea471240-8b9d-4ec2-facb-48544c24fae8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "âœ… System dependencies installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone ComfyUI repository"
      ],
      "metadata": {
        "id": "60zLQ3YfQivU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the installation directory\n",
        "COMFYUI_DIR = \"/content/ComfyUI\"\n",
        "\n",
        "if not os.path.exists(COMFYUI_DIR):\n",
        "    !git clone https://github.com/comfyanonymous/ComfyUI.git {COMFYUI_DIR}\n",
        "    print(\"âœ… ComfyUI cloned successfully!\")\n",
        "else:\n",
        "    print(\"ðŸ“ ComfyUI directory already exists, pulling latest changes...\")\n",
        "    !cd {COMFYUI_DIR} && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLta_5rHQl30",
        "outputId": "d2d9c2d9-8c3b-4ffb-a43f-00771b500a7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ ComfyUI directory already exists, pulling latest changes...\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install ComfyUI requirements"
      ],
      "metadata": {
        "id": "CEXcn_mfQyO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {COMFYUI_DIR}\n",
        "!pip install pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
        "!pip install triton torchaudio\n",
        "!pip install -q -r requirements.txt\n",
        "print(\"âœ… ComfyUI requirements installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvFg0PHqQ0uA",
        "outputId": "8776e485-dca5-4ac6-a657-d191c1194bd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu129\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pip3 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pip3\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchaudio) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchaudio) (3.0.3)\n",
            "âœ… ComfyUI requirements installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_NODES_DIR = f\"{COMFYUI_DIR}/custom_nodes\"\n",
        "MANAGER_DIR = f\"{CUSTOM_NODES_DIR}/ComfyUI-Manager\"\n",
        "\n",
        "if not os.path.exists(MANAGER_DIR):\n",
        "    !git clone https://github.com/ltdrdata/ComfyUI-Manager.git {MANAGER_DIR}\n",
        "    print(\"âœ… ComfyUI Manager installed!\")\n",
        "else:\n",
        "    print(\"ðŸ“ ComfyUI Manager already exists, pulling latest changes...\")\n",
        "    !cd {MANAGER_DIR} && git pull\n",
        "\n",
        "# Install ComfyUI Manager requirements\n",
        "!pip install -q -r {MANAGER_DIR}/requirements.txt 2>/dev/null || true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGKjqMEKRNJz",
        "outputId": "a59ffcb7-0f8f-42e3-e9f4-9bc09b132332"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/ComfyUI/custom_nodes/ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 27645, done.\u001b[K\n",
            "remote: Counting objects: 100% (415/415), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 27645 (delta 327), reused 231 (delta 222), pack-reused 27230 (from 4)\u001b[K\n",
            "Receiving objects: 100% (27645/27645), 122.97 MiB | 14.91 MiB/s, done.\n",
            "Resolving deltas: 100% (20483/20483), done.\n",
            "âœ… ComfyUI Manager installed!\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m432.7/432.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Models"
      ],
      "metadata": {
        "id": "v5zgtooNRQPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://huggingface.co/RunDiffusion/Juggernaut-XL-v9/resolve/main/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors -P ./models/checkpoints/\n",
        "!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "!wget -c https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q4_K_XL.gguf -P ./models/clip/\n",
        "!wget -c https://huggingface.co/unsloth/Z-Image-Turbo-GGUF/resolve/main/z-image-turbo-Q4_K_M.gguf -P ./models/unet/\n",
        "!wget -c https://huggingface.co/Tongyi-MAI/Z-Image-Turbo/resolve/main/vae/diffusion_pytorch_model.safetensors -P ./models/vae/\n",
        "!wget -c https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P ./models/sams/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKUH-aFyRXwy",
        "outputId": "03adadaf-e9a7-4b8d-972f-d8d283264321"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-07 12:31:19--  https://huggingface.co/RunDiffusion/Juggernaut-XL-v9/resolve/main/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.97, 13.35.202.40, 13.35.202.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/65d270fff2da55d0a81123b7/905a020eda0464267780a616dd4fce118cf0c25e53a4f64a7f864c1d502623b3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T122334Z&X-Amz-Expires=3600&X-Amz-Signature=0095b0436208e2ec9325aed8ca05e66cd345039fa638e5e4d21c33c71a43a8fd&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors%3B+filename%3D%22Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors%22%3B&x-id=GetObject&Expires=1767792214&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjIxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NWQyNzBmZmYyZGE1NWQwYTgxMTIzYjcvOTA1YTAyMGVkYTA0NjQyNjc3ODBhNjE2ZGQ0ZmNlMTE4Y2YwYzI1ZTUzYTRmNjRhN2Y4NjRjMWQ1MDI2MjNiMyoifV19&Signature=AwITdCM91wwpgboCUV6C-TyfFRd7jzE-KvmHjvDek4UzNEcPG5VGwhv0b7NkOL9Hi9PNyyw8f%7EqZEILMYgSthRil2mvpLIboafkjBkI74g09N46m8wn924HhLSXyBz6fRYZzfvSYDauNdbRjFN9FetoE8ZrwDvOd7FX%7EyFto6oQ6XIMlBNVBUkgcLOapAJGjT9AQPQ0NvoA7IsO5CzkVdjF6k5fcSOjjO7XrUrGg3T%7EAEm%7Eq-2HVivJU7GQBSE2eJwCHaE0YCwiLO530w-UHkhizxsTmrQiWF-01Ut7nokY7Y1qwtDMn9W50UhZAH6Z%7EjsoQ9NR-QEW6OYl-IiMRgw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-01-07 12:31:19--  https://cas-bridge.xethub.hf.co/xet-bridge-us/65d270fff2da55d0a81123b7/905a020eda0464267780a616dd4fce118cf0c25e53a4f64a7f864c1d502623b3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T122334Z&X-Amz-Expires=3600&X-Amz-Signature=0095b0436208e2ec9325aed8ca05e66cd345039fa638e5e4d21c33c71a43a8fd&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors%3B+filename%3D%22Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors%22%3B&x-id=GetObject&Expires=1767792214&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjIxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NWQyNzBmZmYyZGE1NWQwYTgxMTIzYjcvOTA1YTAyMGVkYTA0NjQyNjc3ODBhNjE2ZGQ0ZmNlMTE4Y2YwYzI1ZTUzYTRmNjRhN2Y4NjRjMWQ1MDI2MjNiMyoifV19&Signature=AwITdCM91wwpgboCUV6C-TyfFRd7jzE-KvmHjvDek4UzNEcPG5VGwhv0b7NkOL9Hi9PNyyw8f%7EqZEILMYgSthRil2mvpLIboafkjBkI74g09N46m8wn924HhLSXyBz6fRYZzfvSYDauNdbRjFN9FetoE8ZrwDvOd7FX%7EyFto6oQ6XIMlBNVBUkgcLOapAJGjT9AQPQ0NvoA7IsO5CzkVdjF6k5fcSOjjO7XrUrGg3T%7EAEm%7Eq-2HVivJU7GQBSE2eJwCHaE0YCwiLO530w-UHkhizxsTmrQiWF-01Ut7nokY7Y1qwtDMn9W50UhZAH6Z%7EjsoQ9NR-QEW6OYl-IiMRgw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.33.45.12, 13.33.45.119, 13.33.45.5, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.33.45.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7105348188 (6.6G)\n",
            "Saving to: â€˜./models/checkpoints/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensorsâ€™\n",
            "\n",
            "Juggernaut-XL_v9_Ru 100%[===================>]   6.62G   331MB/s    in 22s     \n",
            "\n",
            "2026-01-07 12:31:41 (306 MB/s) - â€˜./models/checkpoints/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensorsâ€™ saved [7105348188/7105348188]\n",
            "\n",
            "--2026-01-07 12:31:42--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-07T13%3A21%3A43Z&rscd=attachment%3B+filename%3DRealESRGAN_x4plus.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-07T12%3A21%3A05Z&ske=2026-01-07T13%3A21%3A43Z&sks=b&skv=2018-11-09&sig=XP%2FdbluWBM5U8gh90jr9sAWPQvCyy3Gk6vJEWW8QJ80%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2Nzc5MDkwMiwibmJmIjoxNzY3Nzg5MTAyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.xDRpdVeDMftBQJGGFlZEZFWP-QBZdfZPYuQihTd6AIw&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2026-01-07 12:31:42--  https://release-assets.githubusercontent.com/github-production-release-asset/387326890/08f0e941-ebb7-48f0-9d6a-73e87b710e7e?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-07T13%3A21%3A43Z&rscd=attachment%3B+filename%3DRealESRGAN_x4plus.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-07T12%3A21%3A05Z&ske=2026-01-07T13%3A21%3A43Z&sks=b&skv=2018-11-09&sig=XP%2FdbluWBM5U8gh90jr9sAWPQvCyy3Gk6vJEWW8QJ80%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2Nzc5MDkwMiwibmJmIjoxNzY3Nzg5MTAyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.xDRpdVeDMftBQJGGFlZEZFWP-QBZdfZPYuQihTd6AIw&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67040989 (64M) [application/octet-stream]\n",
            "Saving to: â€˜./models/upscale_models/RealESRGAN_x4plus.pthâ€™\n",
            "\n",
            "RealESRGAN_x4plus.p 100%[===================>]  63.93M   195MB/s    in 0.3s    \n",
            "\n",
            "2026-01-07 12:31:42 (195 MB/s) - â€˜./models/upscale_models/RealESRGAN_x4plus.pthâ€™ saved [67040989/67040989]\n",
            "\n",
            "--2026-01-07 12:31:43--  https://huggingface.co/mradermacher/Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF-GGUF/resolve/main/Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.97, 13.35.202.40, 13.35.202.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/68e173e2f9987db09bef0ae3/e3b285237366d32f4d6d483c4b0129076edf48bdd9f4ef2407f3c3ae5599954d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T123144Z&X-Amz-Expires=3600&X-Amz-Signature=eaad2254d83185d3513259904f1d206379d59fd10ef6f1bc0811fde4608b89c7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.gguf%3B+filename%3D%22Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1767792704&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjcwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGUxNzNlMmY5OTg3ZGIwOWJlZjBhZTMvZTNiMjg1MjM3MzY2ZDMyZjRkNmQ0ODNjNGIwMTI5MDc2ZWRmNDhiZGQ5ZjRlZjI0MDdmM2MzYWU1NTk5OTU0ZCoifV19&Signature=oWS8awDvr8cSJiwXPXYDq0PjMgFg-UJ3tmvDlRx9TCRdpDW096nGFwjwjxHPeGtO%7E7drnoMUzmT%7ERORxI0x4G2x-nAEOMFn1nrmsSvkGD2ZoPz6LBpFMl3IG9Oi7L5ttHLaIGU%7ELVg7FggVeZX1qjQz2Ik%7EK7OLXCo4NDLH%7EwO8v6UsnC4gvPXLtW1mKysTy7BIldY0nkF87GWIfKogfHyKywIOsmu2x2BJkxLZw0iITjIDNUFj41OBkOMxuNcsW8WzEesWMUlViQYdEtwQe1JGg63GIHyP3D2tmqMhq1hoIy9Ll-96HA6ehulbrKXQXsRKtJ7rHKaqVXLl0Tp3C9Q__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-01-07 12:31:44--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68e173e2f9987db09bef0ae3/e3b285237366d32f4d6d483c4b0129076edf48bdd9f4ef2407f3c3ae5599954d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T123144Z&X-Amz-Expires=3600&X-Amz-Signature=eaad2254d83185d3513259904f1d206379d59fd10ef6f1bc0811fde4608b89c7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.gguf%3B+filename%3D%22Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1767792704&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjcwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGUxNzNlMmY5OTg3ZGIwOWJlZjBhZTMvZTNiMjg1MjM3MzY2ZDMyZjRkNmQ0ODNjNGIwMTI5MDc2ZWRmNDhiZGQ5ZjRlZjI0MDdmM2MzYWU1NTk5OTU0ZCoifV19&Signature=oWS8awDvr8cSJiwXPXYDq0PjMgFg-UJ3tmvDlRx9TCRdpDW096nGFwjwjxHPeGtO%7E7drnoMUzmT%7ERORxI0x4G2x-nAEOMFn1nrmsSvkGD2ZoPz6LBpFMl3IG9Oi7L5ttHLaIGU%7ELVg7FggVeZX1qjQz2Ik%7EK7OLXCo4NDLH%7EwO8v6UsnC4gvPXLtW1mKysTy7BIldY0nkF87GWIfKogfHyKywIOsmu2x2BJkxLZw0iITjIDNUFj41OBkOMxuNcsW8WzEesWMUlViQYdEtwQe1JGg63GIHyP3D2tmqMhq1hoIy9Ll-96HA6ehulbrKXQXsRKtJ7rHKaqVXLl0Tp3C9Q__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.33.45.12, 13.33.45.119, 13.33.45.5, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.33.45.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1282435776 (1.2G)\n",
            "Saving to: â€˜./models/clip/Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.ggufâ€™\n",
            "\n",
            "Qwen3ForCausalLM-1. 100%[===================>]   1.19G   277MB/s    in 4.8s    \n",
            "\n",
            "2026-01-07 12:31:49 (254 MB/s) - â€˜./models/clip/Qwen3ForCausalLM-1.7B-from-InternVL3_5-2B-HF.Q4_K_M.ggufâ€™ saved [1282435776/1282435776]\n",
            "\n",
            "--2026-01-07 12:31:49--  https://huggingface.co/unsloth/Z-Image-Turbo-GGUF/resolve/main/z-image-turbo-Q4_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.34, 13.35.202.40, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6948791fc522cdf43eda93f4/67bbc6b3b048bf224a404d3d3f54ee423733521a65548e68609e25c5f0d86756?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T123149Z&X-Amz-Expires=3600&X-Amz-Signature=d1ffd8f79eea8e8689b2d865cb62e9138d363d11328280ef857e0d320fc4bcab&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27z-image-turbo-Q4_K_M.gguf%3B+filename%3D%22z-image-turbo-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1767792709&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjcwOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTQ4NzkxZmM1MjJjZGY0M2VkYTkzZjQvNjdiYmM2YjNiMDQ4YmYyMjRhNDA0ZDNkM2Y1NGVlNDIzNzMzNTIxYTY1NTQ4ZTY4NjA5ZTI1YzVmMGQ4Njc1NioifV19&Signature=HoWoofnS8TLKhTf8%7ECGhq5MRhDMX0-aegSYHlCFg9af0LV2lR0HfMswEjQ-9fufVClGTt3wSaW9It86DkncA3HOTwPsUwhy2xc8X1VGP%7E41lcG6MAruo0B7cig3Gtc-flArtnvnJRAewTWGgG9XspCCx7RzJJN177YrMnEqnCY%7E0P3OK7wEFHfnzDPjcfpd5MIyl%7EaBTh7hJrymmJYKtbrvTz363tFXB3wrWd3SIXJ%7E7sfoGht%7ETYqUCsAEdhsH51cn%7E4vH7b3SpTSg8KFsdDBbLdzMhWv3-tAS8%7EO467Y2vnMVOnupM6w-S2%7EBj3SvDObE-n0B0OORs8V4o2zROvw__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-01-07 12:31:49--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6948791fc522cdf43eda93f4/67bbc6b3b048bf224a404d3d3f54ee423733521a65548e68609e25c5f0d86756?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T123149Z&X-Amz-Expires=3600&X-Amz-Signature=d1ffd8f79eea8e8689b2d865cb62e9138d363d11328280ef857e0d320fc4bcab&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27z-image-turbo-Q4_K_M.gguf%3B+filename%3D%22z-image-turbo-Q4_K_M.gguf%22%3B&x-id=GetObject&Expires=1767792709&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjcwOX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTQ4NzkxZmM1MjJjZGY0M2VkYTkzZjQvNjdiYmM2YjNiMDQ4YmYyMjRhNDA0ZDNkM2Y1NGVlNDIzNzMzNTIxYTY1NTQ4ZTY4NjA5ZTI1YzVmMGQ4Njc1NioifV19&Signature=HoWoofnS8TLKhTf8%7ECGhq5MRhDMX0-aegSYHlCFg9af0LV2lR0HfMswEjQ-9fufVClGTt3wSaW9It86DkncA3HOTwPsUwhy2xc8X1VGP%7E41lcG6MAruo0B7cig3Gtc-flArtnvnJRAewTWGgG9XspCCx7RzJJN177YrMnEqnCY%7E0P3OK7wEFHfnzDPjcfpd5MIyl%7EaBTh7hJrymmJYKtbrvTz363tFXB3wrWd3SIXJ%7E7sfoGht%7ETYqUCsAEdhsH51cn%7E4vH7b3SpTSg8KFsdDBbLdzMhWv3-tAS8%7EO467Y2vnMVOnupM6w-S2%7EBj3SvDObE-n0B0OORs8V4o2zROvw__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.33.45.119, 13.33.45.7, 13.33.45.12, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.33.45.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5030193216 (4.7G)\n",
            "Saving to: â€˜./models/unet/z-image-turbo-Q4_K_M.ggufâ€™\n",
            "\n",
            "z-image-turbo-Q4_K_ 100%[===================>]   4.68G   218MB/s    in 17s     \n",
            "\n",
            "2026-01-07 12:32:06 (288 MB/s) - â€˜./models/unet/z-image-turbo-Q4_K_M.ggufâ€™ saved [5030193216/5030193216]\n",
            "\n",
            "--2026-01-07 12:32:06--  https://huggingface.co/Tongyi-MAI/Z-Image-Turbo/resolve/main/vae/diffusion_pytorch_model.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.34, 13.35.202.40, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/6925c6bcc2b55c92698bf47c/5fc08a93307850a89126de1e284972e1a1d7bcbb061ed06edcfc2db5a2669dcd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T122930Z&X-Amz-Expires=3600&X-Amz-Signature=64efee97dcf61e3c60e730fecaa0c6ef9e738bbd8b3542cf8f4f5cc9d1e6f333&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&x-id=GetObject&Expires=1767792570&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjU3MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTI1YzZiY2MyYjU1YzkyNjk4YmY0N2MvNWZjMDhhOTMzMDc4NTBhODkxMjZkZTFlMjg0OTcyZTFhMWQ3YmNiYjA2MWVkMDZlZGNmYzJkYjVhMjY2OWRjZCoifV19&Signature=g-K8sca3WfwJQ-QigN%7EdWYGxXn6dQjt6eNB5lCMUe5I8SJXNOEQu%7EkAuMgu6GjX%7E79d4t-pAQxv128JIhVLZYlFknXGbfzQQQXFBgp9OzpbdU6VgyTE9o4NnQjxYK8sFJG1rpV8ptl07bp7gc0uE5qZtZNdS6wL3rYYa0khrxzyTAIxwzh2sW859QsuN3RzOFASSJrw%7EZaJMh%7E13pKR%7Eq8hkBHLeVAfhX29KeAMZV3okFMmEXxDkyKpZNkJGFzBJ2qHLcn%7EOctY7cUi%7EjVZ4qQ5PfTVtW9RwSfjIwZARs07XAdH78HzRxXtTS9Ln7B8x8vklsXnUKPS9BOCusL1JAg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2026-01-07 12:32:06--  https://cas-bridge.xethub.hf.co/xet-bridge-us/6925c6bcc2b55c92698bf47c/5fc08a93307850a89126de1e284972e1a1d7bcbb061ed06edcfc2db5a2669dcd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260107%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260107T122930Z&X-Amz-Expires=3600&X-Amz-Signature=64efee97dcf61e3c60e730fecaa0c6ef9e738bbd8b3542cf8f4f5cc9d1e6f333&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&x-id=GetObject&Expires=1767792570&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2Nzc5MjU3MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTI1YzZiY2MyYjU1YzkyNjk4YmY0N2MvNWZjMDhhOTMzMDc4NTBhODkxMjZkZTFlMjg0OTcyZTFhMWQ3YmNiYjA2MWVkMDZlZGNmYzJkYjVhMjY2OWRjZCoifV19&Signature=g-K8sca3WfwJQ-QigN%7EdWYGxXn6dQjt6eNB5lCMUe5I8SJXNOEQu%7EkAuMgu6GjX%7E79d4t-pAQxv128JIhVLZYlFknXGbfzQQQXFBgp9OzpbdU6VgyTE9o4NnQjxYK8sFJG1rpV8ptl07bp7gc0uE5qZtZNdS6wL3rYYa0khrxzyTAIxwzh2sW859QsuN3RzOFASSJrw%7EZaJMh%7E13pKR%7Eq8hkBHLeVAfhX29KeAMZV3okFMmEXxDkyKpZNkJGFzBJ2qHLcn%7EOctY7cUi%7EjVZ4qQ5PfTVtW9RwSfjIwZARs07XAdH78HzRxXtTS9Ln7B8x8vklsXnUKPS9BOCusL1JAg__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.33.45.119, 13.33.45.7, 13.33.45.12, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.33.45.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167666902 (160M)\n",
            "Saving to: â€˜./models/vae/diffusion_pytorch_model.safetensorsâ€™\n",
            "\n",
            "diffusion_pytorch_m 100%[===================>] 159.90M   214MB/s    in 0.7s    \n",
            "\n",
            "2026-01-07 12:32:07 (214 MB/s) - â€˜./models/vae/diffusion_pytorch_model.safetensorsâ€™ saved [167666902/167666902]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Cloudflare for tunnel access"
      ],
      "metadata": {
        "id": "NSt2iu_XR6DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install cloudflared\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb 2>/dev/null\n",
        "!rm cloudflared-linux-amd64.deb\n",
        "print(\"âœ… Cloudflared installed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIBfO-cAR9tm",
        "outputId": "fb0607a8-e0c7-4ec2-e1e8-910210dfb32e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 121763 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.11.1) ...\n",
            "Setting up cloudflared (2025.11.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "âœ… Cloudflared installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Cloudflare tunnel"
      ],
      "metadata": {
        "id": "s_gDYub-SRmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "\n",
        "def start_cloudflared():\n",
        "    \"\"\"Start cloudflared tunnel and print the URL\"\"\"\n",
        "    process = subprocess.Popen(\n",
        "        ['cloudflared', 'tunnel', '--url', 'http://127.0.0.1:8188'],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    for line in process.stderr:\n",
        "        if 'trycloudflare.com' in line:\n",
        "            # Extract URL from the line\n",
        "            match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', line)\n",
        "            if match:\n",
        "                url = match.group(0)\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"ðŸŽ¨ ComfyUI is ready!\")\n",
        "                print(f\"ðŸ”— Access URL: {url}\")\n",
        "                print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Start cloudflared in a separate thread\n",
        "tunnel_thread = threading.Thread(target=start_cloudflared)\n",
        "tunnel_thread.daemon = True\n",
        "tunnel_thread.start()\n",
        "\n",
        "# Give cloudflared a moment to start\n",
        "time.sleep(3)\n",
        "\n",
        "# Change to ComfyUI directory and start\n",
        "%cd {COMFYUI_DIR}\n",
        "\n",
        "# Run ComfyUI\n",
        "# --listen: Allow external connections\n",
        "# --port 8188: Default port\n",
        "# --enable-cors-header: Enable CORS for the tunnel\n",
        "!python main.py --listen --port 8188 --enable-cors-header"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNpic37SSWdN",
        "outputId": "3ff0acdb-dd5f-46ee-e2dc-f5242039ffd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ComfyUI\n",
            "[START] Security scan\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2026-01-07 12:32:16.575\n",
            "** Platform: Linux\n",
            "** Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/__manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   6.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 22693 MB, total RAM 54229 MB\n",
            "pytorch version: 2.9.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using async weight offloading with 2 streams\n",
            "Enabled pinned memory 51517.0\n",
            "working around nvidia conv3d memory bug.\n",
            "Found comfy_kitchen backend triton: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}\n",
            "Found comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}\n",
            "Found comfy_kitchen backend cuda: {'available': False, 'disabled': True, 'unavailable_reason': 'libcublasLt.so.13: cannot open shared object file: No such file or directory', 'capabilities': []}\n",
            "Using pytorch attention\n",
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "ComfyUI version: 0.8.0\n",
            "ComfyUI frontend version: 1.35.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n",
            "Total VRAM 22693 MB, total RAM 54229 MB\n",
            "pytorch version: 2.9.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using async weight offloading with 2 streams\n",
            "Enabled pinned memory 51517.0\n",
            "### Loading: ComfyUI-Manager (V3.39)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.\n",
            "### ComfyUI Version: v0.8.0-2-g3cd7b32f | Released on '2026-01-07'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "To see the GUI go to: http://[::]:8188\n",
            "FETCH ComfyRegistry Data: 5/118\n",
            "FETCH ComfyRegistry Data: 10/118\n",
            "FETCH ComfyRegistry Data: 15/118\n",
            "FETCH ComfyRegistry Data: 20/118\n",
            "FETCH ComfyRegistry Data: 25/118\n",
            "FETCH ComfyRegistry Data: 30/118\n",
            "FETCH ComfyRegistry Data: 35/118\n",
            "FETCH ComfyRegistry Data: 40/118\n",
            "FETCH ComfyRegistry Data: 45/118\n",
            "FETCH ComfyRegistry Data: 50/118\n",
            "FETCH ComfyRegistry Data: 55/118\n",
            "FETCH ComfyRegistry Data: 60/118\n",
            "FETCH ComfyRegistry Data: 65/118\n",
            "FETCH ComfyRegistry Data: 70/118\n",
            "FETCH ComfyRegistry Data: 75/118\n",
            "FETCH ComfyRegistry Data: 80/118\n",
            "FETCH ComfyRegistry Data: 85/118\n",
            "FETCH ComfyRegistry Data: 90/118\n",
            "FETCH ComfyRegistry Data: 95/118\n",
            "FETCH ComfyRegistry Data: 100/118\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "FETCH ComfyRegistry Data: 105/118\n",
            "FETCH ComfyRegistry Data: 110/118\n",
            "FETCH ComfyRegistry Data: 115/118\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "got prompt\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type EPS\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely; 21284.17 MB usable, 1560.80 MB loaded, full load: True\n",
            "Requested to load SDXL\n",
            "loaded completely; 19654.25 MB usable, 4897.05 MB loaded, full load: True\n",
            "100% 20/20 [00:03<00:00,  6.37it/s]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely; 14477.35 MB usable, 159.56 MB loaded, full load: True\n",
            "Prompt executed in 8.13 seconds\n",
            "got prompt\n",
            "100% 20/20 [00:01<00:00, 10.94it/s]\n",
            "Prompt executed in 2.18 seconds\n",
            "got prompt\n",
            "  0% 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchsde/_brownian/brownian_interval.py:608: UserWarning: Should have tb<=t1 but got tb=14.614640235900879 and t1=14.61464.\n",
            "  warnings.warn(f\"Should have {tb_name}<=t1 but got {tb_name}={tb} and t1={self._end}.\")\n",
            " 94% 30/32 [00:03<00:00,  9.46it/s]/usr/local/lib/python3.12/dist-packages/torchsde/_brownian/brownian_interval.py:599: UserWarning: Should have ta>=t0 but got ta=0.1739978790283203 and t0=0.173998.\n",
            "  warnings.warn(f\"Should have ta>=t0 but got ta={ta} and t0={self._start}.\")\n",
            "100% 32/32 [00:03<00:00,  9.37it/s]\n",
            "Prompt executed in 3.70 seconds\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extras.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "100% 35.1k/35.1k [00:00<00:00, 47.5MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "Install: pip packages\n",
            "[ComfyUI-Manager] Using `uv` as Python module for pip operations.\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'gguf>=0.13.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 4 packages in 62ms\n",
            "[!] Prepared 1 package in 8ms\n",
            "[!] Installed 1 package in 4ms\n",
            "[!]  + gguf==0.17.1\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'sentencepiece']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'protobuf']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "FETCH DATA from: /content/ComfyUI/custom_nodes/ComfyUI-Manager/custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "Download: git clone 'https://github.com/wizdroid/wizdroid-character'\n",
            "100% 236.0/236.0 [00:20<00:00, 11.63it/s]\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'requests']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'Pillow']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'numpy']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "[ComfyUI-Manager] skip black listed pip installation: 'torch'\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "Installation was successful.\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "100% 2.64M/2.64M [00:00<00:00, 225MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'segment-anything']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 1 package in 26ms\n",
            "[!] Prepared 1 package in 5ms\n",
            "[!] Installed 1 package in 2ms\n",
            "[!]  + segment-anything==1.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'scikit-image']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'piexif']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 1 package in 31ms\n",
            "[!] Prepared 1 package in 6ms\n",
            "[!] Installed 1 package in 2ms\n",
            "[!]  + piexif==1.1.3\n",
            "[ComfyUI-Manager] skip black listed pip installation: 'transformers'\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'opencv-python-headless']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'scipy']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'dill']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'matplotlib']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'git+https://github.com/facebookresearch/sam2']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 38 packages in 53.63s\n",
            "[!] Prepared 4 packages in 1m 12s\n",
            "[!] Installed 4 packages in 5ms\n",
            "[!]  + hydra-core==1.3.2\n",
            "[!]  + iopath==0.1.10\n",
            "[!]  + portalocker==3.2.0\n",
            "[!]  + sam-2==1.0 (from git+https://github.com/facebookresearch/sam2@2b90b9f5ceec907a1c18123530e92e794ad901a4)\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "Install: install script\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', 'install.py']\n",
            "[!] \n",
            "[!] WARN: The `COMFYUI_MODEL_PATH` environment variable is not set. Assuming `/content/ComfyUI/models` as the ComfyUI path.\n",
            "[!]  ### ComfyUI-Impact-Pack: Check dependencies\n",
            "\n",
            " ### ComfyUI-Impact-Pack: Check basic models\n",
            "[!]   0%|          | 0.00/375M [00:00<?, ?B/s]\n",
            "[!]   4%|â–Ž         | 13.9M/375M [00:00<00:02, 138MB/s]\n",
            "[!]   8%|â–Š         | 29.8M/375M [00:00<00:02, 150MB/s]\n",
            "[!]  12%|â–ˆâ–        | 44.8M/375M [00:00<00:02, 144MB/s]\n",
            "[!]  16%|â–ˆâ–Œ        | 59.2M/375M [00:00<00:02, 136MB/s]\n",
            "[!]  21%|â–ˆâ–ˆâ–       | 80.0M/375M [00:00<00:01, 161MB/s]\n",
            "[!]  26%|â–ˆâ–ˆâ–‹       | 99.0M/375M [00:00<00:01, 170MB/s]\n",
            "[!]  31%|â–ˆâ–ˆâ–ˆ       | 116M/375M [00:00<00:01, 170MB/s] \n",
            "[!]  37%|â–ˆâ–ˆâ–ˆâ–‹      | 139M/375M [00:00<00:01, 190MB/s]\n",
            "[!]  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159M/375M [00:00<00:01, 185MB/s]\n",
            "[!]  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 179M/375M [00:01<00:01, 190MB/s]\n",
            "[!]  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 198M/375M [00:01<00:00, 185MB/s]\n",
            "[!]  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 218M/375M [00:01<00:00, 190MB/s]\n",
            "[!]  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 237M/375M [00:01<00:00, 183MB/s]\n",
            "[!]  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 256M/375M [00:01<00:00, 182MB/s]\n",
            "[!]  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 274M/375M [00:01<00:00, 159MB/s]\n",
            "[!]  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 290M/375M [00:01<00:00, 143MB/s]\n",
            "[!]  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 310M/375M [00:01<00:00, 156MB/s]\n",
            "[!]  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 332M/375M [00:01<00:00, 173MB/s]\n",
            "[!]  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 350M/375M [00:02<00:00, 175MB/s]\n",
            "[!]  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 368M/375M [00:02<00:00, 150MB/s]\n",
            "[!] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375M/375M [00:02<00:00, 165MB/s]\n",
            " ### ComfyUI-Impact-Pack: onnx model directory created (/content/ComfyUI/models/onnx)\n",
            "[!] [W107 12:42:28.206040274 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "100% 99.4k/99.4k [00:00<00:00, 73.7MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'cachetools']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'webcolors']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'opencv-python']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "100% 24.7k/24.7k [00:00<00:00, 41.9MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'ultralytics>=8.3.162']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 50 packages in 184ms\n",
            "[!] Prepared 2 packages in 55ms\n",
            "[!] Installed 2 packages in 9ms\n",
            "[!]  + ultralytics==8.3.249\n",
            "[!]  + ultralytics-thop==2.0.18\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "Install: install script\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', 'install.py']\n",
            "[!] WARNING:root:\n",
            "[!] WARN: The `COMFYUI_MODEL_PATH` environment variable is not set. Assuming `/content/ComfyUI/models` as the ComfyUI path.\n",
            "[!] \n",
            "[!]   0%|          | 0.00/52.0M [00:00<?, ?B/s]\n",
            "[!]  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 25.8M/52.0M [00:00<00:00, 257MB/s]\n",
            "[!] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52.0M/52.0M [00:00<00:00, 336MB/s]\n",
            "[!] \n",
            "[!]   0%|          | 0.00/22.5M [00:00<?, ?B/s]\n",
            "[!] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.5M/22.5M [00:00<00:00, 227MB/s]\n",
            "[!] \n",
            "[!]   0%|          | 0.00/54.8M [00:00<?, ?B/s]\n",
            "[!]  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 23.5M/54.8M [00:00<00:00, 235MB/s]\n",
            "[!] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54.8M/54.8M [00:00<00:00, 325MB/s]\n",
            "[!] [W107 12:43:04.647753866 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 2}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "100% 283k/283k [00:00<00:00, 106MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui_ipadapter_plus\n",
            "100% 53.8M/53.8M [00:02<00:00, 21.0MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/ComfyUI-Copilot\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'sqlalchemy>=1.4.0,<2.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 2 packages in 88ms\n",
            "[!] Prepared 1 package in 42ms\n",
            "[!] Uninstalled 1 package in 12ms\n",
            "[!] Installed 1 package in 6ms\n",
            "[!]  - sqlalchemy==2.0.45\n",
            "[!]  + sqlalchemy==1.4.54\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'python-dotenv>=0.19.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'openai>=1.5.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 12ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'requests>=2.25.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'aiohttp>=3.8.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'httpx>=0.24.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'pytest>=6.0.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'pytest-asyncio>=0.18.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 7 packages in 36ms\n",
            "[!] Prepared 1 package in 4ms\n",
            "[!] Installed 1 package in 2ms\n",
            "[!]  + pytest-asyncio==1.3.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'openai-agents>=0.3.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 41 packages in 250ms\n",
            "[!] Prepared 4 packages in 24ms\n",
            "[!] Installed 4 packages in 5ms\n",
            "[!]  + colorama==0.4.6\n",
            "[!]  + griffe==1.15.0\n",
            "[!]  + openai-agents==0.6.5\n",
            "[!]  + types-requests==2.32.4.20260107\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'langsmith>=0.4.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'fastmcp']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 84 packages in 4.90s\n",
            "[!] Prepared 24 packages in 1.54s\n",
            "[!] Uninstalled 5 packages in 16ms\n",
            "[!] Installed 24 packages in 11ms\n",
            "[!]  + cyclopts==4.4.4\n",
            "[!]  + diskcache==5.6.3\n",
            "[!]  + dnspython==2.8.0\n",
            "[!]  + email-validator==2.3.0\n",
            "[!]  + exceptiongroup==1.3.1\n",
            "[!]  + fakeredis==2.33.0\n",
            "[!]  + fastmcp==2.14.2\n",
            "[!]  + jsonschema-path==0.3.4\n",
            "[!]  + lupa==2.6\n",
            "[!]  + openapi-pydantic==0.5.1\n",
            "[!]  - opentelemetry-api==1.37.0\n",
            "[!]  + opentelemetry-api==1.39.1\n",
            "[!]  + opentelemetry-exporter-prometheus==0.60b1\n",
            "[!]  + opentelemetry-instrumentation==0.60b1\n",
            "[!]  - opentelemetry-sdk==1.37.0\n",
            "[!]  + opentelemetry-sdk==1.39.1\n",
            "[!]  - opentelemetry-semantic-conventions==0.58b0\n",
            "[!]  + opentelemetry-semantic-conventions==0.60b1\n",
            "[!]  + pathable==0.4.4\n",
            "[!]  + pathvalidate==3.3.1\n",
            "[!]  + py-key-value-aio==0.3.0\n",
            "[!]  + py-key-value-shared==0.3.0\n",
            "[!]  + pydocket==0.16.3\n",
            "[!]  + redis==7.1.0\n",
            "[!]  - referencing==0.37.0\n",
            "[!]  + referencing==0.36.2\n",
            "[!]  + rich-rst==1.3.2\n",
            "[!]  - wrapt==2.0.1\n",
            "[!]  + wrapt==1.17.3\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'modelscope>=1.28.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 9 packages in 26ms\n",
            "[!] Prepared 1 package in 363ms\n",
            "[!] Installed 1 package in 67ms\n",
            "[!]  + modelscope==1.33.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'urllib3>=1.26,<2.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 1 package in 12ms\n",
            "[!] Prepared 1 package in 8ms\n",
            "[!] Uninstalled 1 package in 2ms\n",
            "[!] Installed 1 package in 3ms\n",
            "[!]  - urllib3==2.5.0\n",
            "[!]  + urllib3==1.26.20\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "100% 39.8M/39.8M [00:01<00:00, 30.8MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'importlib_metadata']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'huggingface_hub']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 12ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'opencv-python>=4.7.0.72']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 12ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'filelock']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'einops']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "[ComfyUI-Manager] skip black listed pip installation: 'torchvision'\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'pyyaml']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'python-dateutil']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'mediapipe']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 7 packages in 38ms\n",
            "[!] Prepared 3 packages in 1.74s\n",
            "[!] Uninstalled 1 package in 2ms\n",
            "[!] Installed 3 packages in 5ms\n",
            "[!]  - absl-py==1.4.0\n",
            "[!]  + absl-py==2.3.1\n",
            "[!]  + mediapipe==0.10.31\n",
            "[!]  + sounddevice==0.5.3\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'fvcore']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 11 packages in 4.06s\n",
            "[!] Prepared 2 packages in 274ms\n",
            "[!] Installed 2 packages in 1ms\n",
            "[!]  + fvcore==0.1.5.post20221221\n",
            "[!]  + yacs==0.1.8\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'yapf']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 2 packages in 24ms\n",
            "[!] Prepared 1 package in 14ms\n",
            "[!] Installed 1 package in 5ms\n",
            "[!]  + yapf==0.43.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'omegaconf']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 10ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'ftfy']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 2 packages in 32ms\n",
            "[!] Prepared 1 package in 9ms\n",
            "[!] Installed 1 package in 3ms\n",
            "[!]  + ftfy==6.3.1\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'addict']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 1 package in 24ms\n",
            "[!] Prepared 1 package in 7ms\n",
            "[!] Installed 1 package in 2ms\n",
            "[!]  + addict==2.4.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'yacs']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'trimesh']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 31 packages in 221ms\n",
            "[!] Prepared 8 packages in 217ms\n",
            "[!] Installed 8 packages in 7ms\n",
            "[!]  + colorlog==6.10.1\n",
            "[!]  + embreex==2.17.7.post7\n",
            "[!]  + manifold3d==3.3.2\n",
            "[!]  + mapbox-earcut==2.0.0\n",
            "[!]  + pycollada==0.9.2\n",
            "[!]  + svg-path==7.0\n",
            "[!]  + trimesh==4.10.1\n",
            "[!]  + vhacdx==0.0.10\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'albumentations']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'scikit-learn']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "100% 161M/161M [00:12<00:00, 13.3MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/fastvideo\n",
            "100% 369k/369k [00:00<00:00, 7.21MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/ComfyUI-nunchaku\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'diffusers>=0.35']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'transformers>=4.54']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'huggingface_hub>=0.34']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 12ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'tomli']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 1 package in 288ms\n",
            "[!] Prepared 1 package in 8ms\n",
            "[!] Installed 1 package in 2ms\n",
            "[!]  + tomli==2.3.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'peft>=0.17']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 15ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'accelerate>=1.10']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 14ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'insightface']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 45 packages in 3.15s\n",
            "[!] Prepared 2 packages in 4.45s\n",
            "[!] Installed 2 packages in 259ms\n",
            "[!]  + insightface==0.7.3\n",
            "[!]  + onnx==1.20.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'facexlib']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 45 packages in 699ms\n",
            "[!] Prepared 2 packages in 285ms\n",
            "[!] Installed 2 packages in 1ms\n",
            "[!]  + facexlib==0.3.0\n",
            "[!]  + filterpy==1.4.5\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'onnxruntime']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 9 packages in 69ms\n",
            "[!] Prepared 3 packages in 351ms\n",
            "[!] Installed 3 packages in 8ms\n",
            "[!]  + coloredlogs==15.0.1\n",
            "[!]  + humanfriendly==10.0\n",
            "[!]  + onnxruntime==1.23.2\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'timm']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "100% 4.05M/4.05M [00:00<00:00, 221MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/rgthree-comfy\n",
            "Install: pip packages\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "100% 1.24M/1.24M [00:00<00:00, 194MB/s]\n",
            "Extracted zip file to /content/ComfyUI/custom_nodes/comfyui-supir\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'transformers>=4.28.1']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 13ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'open-clip-torch>=2.24.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 45 packages in 106ms\n",
            "[!] Prepared 1 package in 47ms\n",
            "[!] Installed 1 package in 4ms\n",
            "[!]  + open-clip-torch==3.2.0\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'Pillow>=9.4.0']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 11ms\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'pytorch-lightning>=2.2.1']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Resolved 42 packages in 188ms\n",
            "[!] Prepared 3 packages in 61ms\n",
            "[!] Installed 3 packages in 8ms\n",
            "[!]  + lightning-utilities==0.15.2\n",
            "[!]  + pytorch-lightning==2.6.0\n",
            "[!]  + torchmetrics==1.8.2\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'uv', 'pip', \n",
            "'install', 'accelerate']\n",
            "[!] Using Python 3.12.12 environment at: /usr\n",
            "[!] Audited 1 package in 14ms\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 7}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--listen', '--port', '8188', '--enable-cors-header']\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "[START] Security scan\n",
            "[ComfyUI-Manager] Using `uv` as Python module for pip operations.\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2026-01-07 12:45:37.551\n",
            "** Platform: Linux\n",
            "** Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/ComfyUI\n",
            "** User directory: /content/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/ComfyUI/user/__manager/config.ini\n",
            "** Log path: /content/ComfyUI/user/comfyui.log\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.8 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 22693 MB, total RAM 54229 MB\n",
            "pytorch version: 2.9.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using async weight offloading with 2 streams\n",
            "Enabled pinned memory 51517.0\n",
            "working around nvidia conv3d memory bug.\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "Found comfy_kitchen backend cuda: {'available': False, 'disabled': True, 'unavailable_reason': 'libcublasLt.so.13: cannot open shared object file: No such file or directory', 'capabilities': []}\n",
            "Found comfy_kitchen backend eager: {'available': True, 'disabled': False, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8', 'scaled_mm_nvfp4']}\n",
            "Found comfy_kitchen backend triton: {'available': True, 'disabled': True, 'unavailable_reason': None, 'capabilities': ['apply_rope', 'apply_rope1', 'dequantize_nvfp4', 'dequantize_per_tensor_fp8', 'quantize_nvfp4', 'quantize_per_tensor_fp8']}\n",
            "Using pytorch attention\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "ComfyUI version: 0.8.0\n",
            "ComfyUI frontend version: 1.35.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.12/dist-packages/comfyui_frontend_package/static\n",
            "Total VRAM 22693 MB, total RAM 54229 MB\n",
            "pytorch version: 2.9.0+cu126\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 NVIDIA L4 : cudaMallocAsync\n",
            "Using async weight offloading with 2 streams\n",
            "Enabled pinned memory 51517.0\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "======================================== ComfyUI-nunchaku Initialization ========================================\n",
            "Nunchaku version: Package 'nunchaku' not found.\n",
            "ComfyUI-nunchaku version: 1.1.0\n",
            "Could not parse nunchaku version: Package 'nunchaku' not found.. Please ensure you have at least v1.0.0.\n",
            "Node `NunchakuFluxDiTLoader` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 82, in <module>\n",
            "    from .nodes.models.flux import NunchakuFluxDiTLoader\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/flux.py\", line 16, in <module>\n",
            "    from nunchaku import NunchakuFluxTransformer2dModel\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Node `NunchakuQwenImageDiTLoader` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 89, in <module>\n",
            "    from .nodes.models.qwenimage import NunchakuQwenImageDiTLoader\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/qwenimage.py\", line 13, in <module>\n",
            "    from nunchaku.utils import check_hardware_compatibility, get_gpu_memory, get_precision_from_quantization_config\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Nodes `NunchakuFluxLoraLoader` and `NunchakuFluxLoraStack` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 96, in <module>\n",
            "    from .nodes.lora.flux import NunchakuFluxLoraLoader, NunchakuFluxLoraStack\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/lora/flux.py\", line 9, in <module>\n",
            "    from nunchaku.lora.flux import to_diffusers\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Nodes `NunchakuTextEncoderLoader` and `NunchakuTextEncoderLoaderV2` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 104, in <module>\n",
            "    from .nodes.models.text_encoder import NunchakuTextEncoderLoader, NunchakuTextEncoderLoaderV2\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/text_encoder.py\", line 18, in <module>\n",
            "    from nunchaku import NunchakuT5EncoderModel\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Nodes `NunchakuPulidApply`,`NunchakuPulidLoader`, `NunchakuPuLIDLoaderV2` and `NunchakuFluxPuLIDApplyV2` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 119, in <module>\n",
            "    from .nodes.models.pulid import (\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/pulid.py\", line 19, in <module>\n",
            "    from nunchaku.models.pulid.pulid_forward import pulid_forward\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "2026-01-07 12:45:51.060076: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-07 12:45:51.076970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767789951.099477    7177 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767789951.106603    7177 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767789951.123864    7177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767789951.123913    7177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767789951.123917    7177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767789951.123921    7177 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-07 12:45:51.128972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NumExpr defaulting to 12 threads.\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Nodes `NunchakuFluxIPAdapterApply` and `NunchakuIPAdapterLoader` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 136, in <module>\n",
            "    from .nodes.models.ipadapter import NunchakuFluxIPAdapterApply, NunchakuIPAdapterLoader\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/ipadapter.py\", line 14, in <module>\n",
            "    from nunchaku.models.ip_adapter.diffusers_adapters import apply_IPA_on_pipe\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Nodes `NunchakuZImageDiTLoader` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 144, in <module>\n",
            "    from .nodes.models.zimage import NunchakuZImageDiTLoader\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/models/zimage.py\", line 12, in <module>\n",
            "    from nunchaku.models.transformers.utils import patch_scale_key\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "Node `NunchakuModelMerger` import failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/__init__.py\", line 151, in <module>\n",
            "    from .nodes.tools.merge_safetensors import NunchakuModelMerger\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-nunchaku/nodes/tools/merge_safetensors.py\", line 10, in <module>\n",
            "    from nunchaku.merge_safetensors import merge_safetensors\n",
            "ModuleNotFoundError: No module named 'nunchaku'\n",
            "'nunchaku_versions.json' not found. Node will start in minimal mode. Use 'update node' to fetch versions.\n",
            "=================================================================================================================\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.23)\n",
            "ComfyUI-GGUF: Allowing full torch compile\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 48 exciting nodes. ðŸŽ‰\u001b[0m\n",
            "\n",
            "\u001b[33m[rgthree-comfy] ComfyUI's new Node 2.0 rendering may be incompatible with some rgthree-comfy nodes and features, breaking some rendering as well as losing the ability to access a node's properties (a vital part of many nodes). It also appears to run MUCH more slowly spiking CPU usage and causing jankiness and unresponsiveness, especially with large workflows. Personally I am not planning to use the new Nodes 2.0 and, unfortunately, am not able to invest the time to investigate and overhaul rgthree-comfy where needed. If you have issues when Nodes 2.0 is enabled, I'd urge you to switch it off as well and join me in hoping ComfyUI is not planning to deprecate the existing, stable canvas rendering all together.\n",
            "\u001b[0m\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¨ ComfyUI is ready!\n",
            "ðŸ”— Access URL: https://stuff-advertise-album-abu.trycloudflare.com\n",
            "============================================================\n",
            "\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "\u001b[36;20m[/content/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "/content/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/dwpose.py:26: UserWarning: DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\n",
            "  warnings.warn(\"DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\")\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.3.5)\n",
            "[Impact Pack/Subpack] Using folder_paths to determine whitelist path: /content/ComfyUI/user/default/ComfyUI-Impact-Subpack/model-whitelist.txt\n",
            "[Impact Pack/Subpack] Ensured whitelist directory exists: /content/ComfyUI/user/default/ComfyUI-Impact-Subpack\n",
            "[Impact Pack/Subpack] Model whitelist file not found at: /content/ComfyUI/user/default/ComfyUI-Impact-Subpack/model-whitelist.txt. \n",
            " >> An empty whitelist file will be created.\n",
            " >> To allow unsafe loading for specific trusted legacy models (e.g., older .pt),\n",
            " >> add their base filenames (one per line) to this file.\n",
            "[Impact Pack/Subpack] Created empty whitelist file: /content/ComfyUI/user/default/ComfyUI-Impact-Subpack/model-whitelist.txt\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "[Impact Subpack] ultralytics_bbox: /content/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/ComfyUI/models/ultralytics/segm\n",
            "### Loading: ComfyUI-Impact-Pack (V8.28.2)\n",
            "[Impact Pack] Wildcard total size (0.00 MB) is within cache limit (50.00 MB). Using full cache mode.\n",
            "[Impact Pack] Wildcards loading done.\n",
            "### Loading: ComfyUI-Manager (V3.39)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "[ComfyUI-Manager] ComfyUI per-queue preview override detected (PR #11261). Manager's preview method feature is disabled. Use ComfyUI's --preview-method CLI option or 'Settings > Execution > Live preview method'.\n",
            "### ComfyUI Version: v0.8.0-2-g3cd7b32f | Released on '2026-01-07'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/fastvideo\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/comfyui_ipadapter_plus\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/wizdroid-character\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.1 seconds: /content/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.3 seconds: /content/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.4 seconds: /content/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   4.5 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Copilot\n",
            "   7.4 seconds: /content/ComfyUI/custom_nodes/comfyui-supir\n",
            "  12.3 seconds: /content/ComfyUI/custom_nodes/ComfyUI-nunchaku\n",
            "\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "Context impl SQLiteImpl.\n",
            "Will assume non-transactional DDL.\n",
            "No target revision found.\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "Starting server\n",
            "\n",
            "To see the GUI go to: http://0.0.0.0:8188\n",
            "To see the GUI go to: http://[::]:8188\n",
            "FETCH ComfyRegistry Data: 5/118\n",
            "FETCH ComfyRegistry Data: 10/118\n",
            "FETCH ComfyRegistry Data: 15/118\n",
            "FETCH ComfyRegistry Data: 20/118\n",
            "FETCH ComfyRegistry Data: 25/118\n",
            "FETCH ComfyRegistry Data: 30/118\n",
            "FETCH ComfyRegistry Data: 35/118\n",
            "FETCH ComfyRegistry Data: 40/118\n",
            "FETCH ComfyRegistry Data: 45/118\n",
            "FETCH ComfyRegistry Data: 50/118\n",
            "FETCH ComfyRegistry Data: 55/118\n",
            "FETCH ComfyRegistry Data: 60/118\n",
            "FETCH ComfyRegistry Data: 65/118\n",
            "FETCH ComfyRegistry Data: 70/118\n",
            "FETCH ComfyRegistry Data: 75/118\n",
            "FETCH ComfyRegistry Data: 80/118\n",
            "FETCH ComfyRegistry Data: 85/118\n",
            "FETCH ComfyRegistry Data: 90/118\n",
            "FETCH ComfyRegistry Data: 95/118\n",
            "FETCH ComfyRegistry Data: 100/118\n",
            "FETCH ComfyRegistry Data: 105/118\n",
            "FETCH ComfyRegistry Data: 110/118\n",
            "FETCH ComfyRegistry Data: 115/118\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/clipspace.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /extensions/core/groupNode.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/buttonGroup.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "[DEPRECATION WARNING] Detected import of deprecated legacy API: /scripts/ui/components/button.js. This is likely caused by a custom node extension using outdated APIs. Please update your extensions or contact the extension author for an updated version.\n",
            "2026-01-07 12:49:08 | INFO     | llm_api.py:list_models:36 | Received list_models request\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:save_workflow_checkpoint:371 | Received save-workflow-checkpoint request\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:save_workflow_checkpoint:410 | Workflow checkpoint saved with version ID: 1\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:invoke_chat:222 | Received invoke_chat request\n",
            "2026-01-07 12:49:52 | INFO     | auth_utils.py:extract_and_store_api_key:27 | ComfyUI Copilot API key extracted and stored: null...\n",
            "2026-01-07 12:49:52 | INFO     | auth_utils.py:extract_and_store_api_key:32 | API key verification: Successfully stored in globals\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:invoke_chat:228 | Request JSON:\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:invoke_chat:272 | -- Received 1 historical messages\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:invoke_chat:276 | Using workflow checkpoint ID: 1 for session d989e4da-8b3c-4310-9a98-53d2a9f308d8\n",
            "2026-01-07 12:49:52 | INFO     | conversation_api.py:invoke_chat:295 | config: {'session_id': 'd989e4da-8b3c-4310-9a98-53d2a9f308d8', 'workflow_checkpoint_id': 1, 'openai_api_key': '', 'openai_base_url': None, 'workflow_llm_api_key': None, 'workflow_llm_base_url': None, 'workflow_llm_model': 'us.anthropic.claude-sonnet-4-20250514-v1:0', 'model_select': 'gemini-2.5-flash'}\n",
            "2026-01-07 12:49:52 | INFO     | mcp_client.py:comfyui_agent_invoke:116 | [MCP] Original messages count: 1\n",
            "2026-01-07 12:49:52 | INFO     | message_memory.py:message_memory_optimize:49 | [Memory] Starting memory optimization for session: d989e4da-8b3c-4310-9a98-53d2a9f308d8\n",
            "2026-01-07 12:49:52 | INFO     | message_memory.py:message_memory_optimize:50 | [Memory] Input messages count: 1\n",
            "2026-01-07 12:49:52 | INFO     | message_memory.py:message_memory_optimize:57 | [Memory] New session detected, creating record\n",
            "2026-01-07 12:49:52 | INFO     | mcp_client.py:comfyui_agent_invoke:118 | [MCP] Optimized messages count: 1, messages: [{'role': 'user', 'content': 'Add face detailer'}]\n",
            "HTTP Request: GET https://comfyui-copilot-server.onrender.com/mcp-server/mcp \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://comfyui-copilot-server.onrender.com/mcp-server/messages/?session_id=24cec8cac3484fc3932d09ba697df5bf \"HTTP/1.1 202 Accepted\"\n",
            "HTTP Request: POST https://comfyui-copilot-server.onrender.com/mcp-server/messages/?session_id=24cec8cac3484fc3932d09ba697df5bf \"HTTP/1.1 202 Accepted\"\n",
            "HTTP Request: GET https://mcp.api-inference.modelscope.net/8c9fe550938e4f/sse \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mcp.api-inference.modelscope.net/messages/?session_id=5d44f643e314410b80e19affc70de1b9 \"HTTP/1.1 202 Accepted\"\n",
            "2026-01-07 12:49:54 | INFO     | mcp_client.py:comfyui_agent_invoke:301 | -- Processing 1 messages\n",
            "2026-01-07 12:49:54 | INFO     | mcp_client.py:comfyui_agent_invoke:314 | === MCP Agent Run starting ===\n",
            "2026-01-07 12:49:54 | INFO     | mcp_client.py:process_stream_events:354 | Handoff to: ComfyUI-Copilot\n",
            "HTTP Request: POST https://comfyui-copilot-server.onrender.com/mcp-server/messages/?session_id=24cec8cac3484fc3932d09ba697df5bf \"HTTP/1.1 202 Accepted\"\n",
            "HTTP Request: POST https://mcp.api-inference.modelscope.net/messages/?session_id=5d44f643e314410b80e19affc70de1b9 \"HTTP/1.1 202 Accepted\"\n",
            "HTTP Request: POST https://mcp.api-inference.modelscope.net/messages/?session_id=5d44f643e314410b80e19affc70de1b9 \"HTTP/1.1 202 Accepted\"\n",
            "HTTP Request: POST https://comfyui-copilot-server.onrender.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
            "2026-01-07 12:49:56 | ERROR    | mcp_client.py:process_stream_events:453 | Unexpected streaming error: Error code: 401 - You are not authorized, please click âš™ï¸ to send email, and get the Key from the email to configure your Key.\n",
            "2026-01-07 12:49:56 | ERROR    | mcp_client.py:process_stream_events:454 | Traceback: Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-Copilot/backend/service/mcp_client.py\", line 338, in process_stream_events\n",
            "    async for event in stream_result.stream_events():\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/result.py\", line 355, in stream_events\n",
            "    raise self._stored_exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/run.py\", line 1204, in _start_streaming\n",
            "    turn_result = await cls._run_single_turn_streamed(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/run.py\", line 1446, in _run_single_turn_streamed\n",
            "    async for event in model.stream_response(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/models/openai_chatcompletions.py\", line 185, in stream_response\n",
            "    response, stream = await self._fetch_response(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/models/openai_chatcompletions.py\", line 321, in _fetch_response\n",
            "    ret = await self._get_client().chat.completions.create(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2678, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.AuthenticationError: Error code: 401 - You are not authorized, please click âš™ï¸ to send email, and get the Key from the email to configure your Key.\n",
            "\n",
            "2026-01-07 12:49:56 | ERROR    | mcp_client.py:comfyui_agent_invoke:503 | Non-retryable streaming error or max retries reached: Error code: 401 - You are not authorized, please click âš™ï¸ to send email, and get the Key from the email to configure your Key.\n",
            "2026-01-07 12:49:56 | ERROR    | mcp_client.py:comfyui_agent_invoke:504 | Traceback: Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-Copilot/backend/service/mcp_client.py\", line 460, in comfyui_agent_invoke\n",
            "    async for stream_data in process_stream_events(result):\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-Copilot/backend/service/mcp_client.py\", line 455, in process_stream_events\n",
            "    raise e\n",
            "  File \"/content/ComfyUI/custom_nodes/ComfyUI-Copilot/backend/service/mcp_client.py\", line 338, in process_stream_events\n",
            "    async for event in stream_result.stream_events():\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/result.py\", line 355, in stream_events\n",
            "    raise self._stored_exception\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/run.py\", line 1204, in _start_streaming\n",
            "    turn_result = await cls._run_single_turn_streamed(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/run.py\", line 1446, in _run_single_turn_streamed\n",
            "    async for event in model.stream_response(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/models/openai_chatcompletions.py\", line 185, in stream_response\n",
            "    response, stream = await self._fetch_response(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/agents/models/openai_chatcompletions.py\", line 321, in _fetch_response\n",
            "    ret = await self._get_client().chat.completions.create(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 2678, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1794, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1594, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.AuthenticationError: Error code: 401 - You are not authorized, please click âš™ï¸ to send email, and get the Key from the email to configure your Key.\n",
            "\n",
            "2026-01-07 12:49:56 | INFO     | mcp_client.py:comfyui_agent_invoke:530 | Total tool results: 0\n",
            "2026-01-07 12:49:56 | INFO     | mcp_client.py:comfyui_agent_invoke:540 | === End Tool Results Summary ===\n",
            "\n",
            "2026-01-07 12:49:56 | INFO     | conversation_api.py:invoke_chat:310 | -- Received ext data: None, finished: True\n",
            "2026-01-07 12:49:56 | INFO     | conversation_api.py:invoke_chat:335 | -- Sending final response: 0 chars, ext: False, finished: True\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/832903789_extras.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "FETCH DATA from: /content/ComfyUI/user/__manager/cache/4245046894_model-list.json [DONE]\n",
            "got prompt\n",
            "Loads SAM model: /content/ComfyUI/models/sams/sam_vit_b_01ec64.pth (device:AUTO)\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type EPS\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "Requested to load SDXLClipModel\n",
            "loaded completely; 21284.17 MB usable, 1560.80 MB loaded, full load: True\n",
            "Requested to load SDXL\n",
            "loaded completely; 19606.37 MB usable, 4897.05 MB loaded, full load: True\n",
            "  0% 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torchsde/_brownian/brownian_interval.py:608: UserWarning: Should have tb<=t1 but got tb=14.614640235900879 and t1=14.61464.\n",
            "  warnings.warn(f\"Should have {tb_name}<=t1 but got {tb_name}={tb} and t1={self._end}.\")\n",
            " 94% 30/32 [00:05<00:00,  5.90it/s]/usr/local/lib/python3.12/dist-packages/torchsde/_brownian/brownian_interval.py:599: UserWarning: Should have ta>=t0 but got ta=0.1739978790283203 and t0=0.173998.\n",
            "  warnings.warn(f\"Should have ta>=t0 but got ta={ta} and t0={self._start}.\")\n",
            "100% 32/32 [00:05<00:00,  5.46it/s]\n",
            "Requested to load AutoencoderKL\n",
            "loaded completely; 14429.48 MB usable, 159.56 MB loaded, full load: True\n",
            "\n",
            "0: 640x640 1 face, 12.3ms\n",
            "Speed: 44.0ms preprocess, 12.3ms inference, 9.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(257.91766), np.float32(331.26855))) | crop region (512, 512) x 1.9851295948028564 -> (1016, 1016)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 20/20 [00:06<00:00,  2.86it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 33.07 seconds\n",
            "got prompt\n",
            "100% 32/32 [00:05<00:00,  5.79it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(253.19083), np.float32(343.04648))) | crop region (512, 512) x 2.0006980895996094 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.95it/s]\n",
            "[Impact Pack] vae decoded in 0.5s\n",
            "Prompt executed in 10.67 seconds\n",
            "got prompt\n",
            "100% 32/32 [00:05<00:00,  5.78it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(176.59743), np.float32(212.9859))) | crop region (512, 512) x 2.0005602836608887 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.95it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.66 seconds\n",
            "got prompt\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(302.9849), np.float32(261.2964))) | crop region (512, 512) x 1.959460735321045 -> (1003, 1003)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.96it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.65 seconds\n",
            "got prompt\n",
            "  3% 1/32 [00:00<00:05,  5.58it/s]got prompt\n",
            " 28% 9/32 [00:01<00:04,  5.67it/s]got prompt\n",
            " 41% 13/32 [00:02<00:03,  5.67it/s]got prompt\n",
            " 56% 18/32 [00:03<00:02,  5.72it/s]got prompt\n",
            " 72% 23/32 [00:04<00:01,  5.82it/s]got prompt\n",
            " 81% 26/32 [00:04<00:01,  5.81it/s]got prompt\n",
            " 97% 31/32 [00:05<00:00,  5.89it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.74it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(215.48024), np.float32(298.4501))) | crop region (512, 512) x 2.0009162425994873 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 10% 1/10 [00:00<00:01,  6.24it/s]got prompt\n",
            " 60% 6/10 [00:01<00:01,  2.87it/s]got prompt\n",
            "100% 10/10 [00:03<00:00,  2.95it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.68 seconds\n",
            "got prompt\n",
            " 19% 6/32 [00:01<00:04,  5.80it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.71it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(146.82707), np.float32(206.82733))) | crop region (440, 512) x 2.0004401206970215 -> (880, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 90% 9/10 [00:02<00:00,  3.37it/s]got prompt\n",
            "100% 10/10 [00:02<00:00,  3.47it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.01 seconds\n",
            " 41% 13/32 [00:02<00:03,  5.66it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.76it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(140.67169), np.float32(191.49493))) | crop region (422, 512) x 2.000554323196411 -> (844, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 30% 3/10 [00:00<00:01,  3.78it/s]got prompt\n",
            "100% 10/10 [00:02<00:00,  3.40it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 10.02 seconds\n",
            " 28% 9/32 [00:01<00:04,  5.61it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.73it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(187.96979), np.float32(270.39218))) | crop region (512, 512) x 2.000870943069458 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.91it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.74 seconds\n",
            " 56% 18/32 [00:03<00:02,  5.74it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.70it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(187.40118), np.float32(252.85675))) | crop region (512, 512) x 2.001199722290039 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 90% 9/10 [00:03<00:00,  2.75it/s]got prompt\n",
            "100% 10/10 [00:03<00:00,  2.90it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.78 seconds\n",
            " 56% 18/32 [00:03<00:02,  5.56it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.54it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(214.9559), np.float32(255.32095))) | crop region (512, 512) x 2.0008606910705566 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.90it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.97 seconds\n",
            " 44% 14/32 [00:02<00:03,  5.63it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.61it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(144.90395), np.float32(186.37292))) | crop region (434, 512) x 2.0000972747802734 -> (868, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  3.30it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.27 seconds\n",
            " 53% 17/32 [00:03<00:02,  5.63it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.65it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(301.00616), np.float32(375.90488))) | crop region (512, 512) x 1.7009618282318115 -> (870, 870)\n",
            "[Impact Pack] vae encoded in 0.2s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:02<00:00,  3.84it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 9.66 seconds\n",
            " 97% 31/32 [00:05<00:00,  5.72it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.66it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(180.24825), np.float32(226.19159))) | crop region (512, 512) x 2.000481128692627 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.86it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.89 seconds\n",
            "100% 32/32 [00:05<00:00,  5.67it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "got prompt\n",
            "Detailer: segment upscale for ((np.float32(397.32236), np.float32(414.61313))) | crop region (512, 512) x 1.2886261940002441 -> (659, 659)\n",
            "[Impact Pack] vae encoded in 0.1s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:01<00:00,  5.45it/s]\n",
            "[Impact Pack] vae decoded in 0.2s\n",
            "Prompt executed in 8.50 seconds\n",
            " 81% 26/32 [00:04<00:01,  5.80it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.78it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(111.07292), np.float32(170.45076))) | crop region (333, 511) x 2.0043373107910156 -> (667, 1024)\n",
            "[Impact Pack] vae encoded in 0.2s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:02<00:00,  4.41it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 9.09 seconds\n",
            "100% 32/32 [00:05<00:00,  5.77it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(194.831), np.float32(281.06036))) | crop region (512, 512) x 2.00073504447937 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 60% 6/10 [00:02<00:01,  2.76it/s]got prompt\n",
            "100% 10/10 [00:03<00:00,  2.84it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.81 seconds\n",
            " 19% 6/32 [00:01<00:04,  5.70it/s]got prompt\n",
            " 84% 27/32 [00:04<00:00,  5.72it/s]got prompt\n",
            "100% 32/32 [00:05<00:00,  5.75it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(247.05284), np.float32(370.39398))) | crop region (512, 512) x 2.000159740447998 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.84it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.83 seconds\n",
            "100% 32/32 [00:05<00:00,  5.80it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(155.63184), np.float32(213.65137))) | crop region (466, 512) x 2.000458002090454 -> (932, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  3.02it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.45 seconds\n",
            "100% 32/32 [00:05<00:00,  5.82it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(263.33527), np.float32(350.84064))) | crop region (512, 512) x 1.9442895650863647 -> (995, 995)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.93it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.59 seconds\n",
            "100% 32/32 [00:05<00:00,  5.80it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(254.03702), np.float32(319.4294))) | crop region (512, 512) x 2.001770257949829 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.82it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.81 seconds\n",
            "100% 32/32 [00:05<00:00,  5.76it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(193.30652), np.float32(253.43398))) | crop region (512, 512) x 2.000155448913574 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.82it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.85 seconds\n",
            "100% 32/32 [00:05<00:00,  5.77it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.2ms\n",
            "Speed: 2.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(169.85782), np.float32(242.87508))) | crop region (509, 512) x 2.0004074573516846 -> (1018, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.80it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.86 seconds\n",
            "100% 32/32 [00:05<00:00,  5.78it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(102.91066), np.float32(145.12848))) | crop region (308, 435) x 2.354248523712158 -> (725, 1024)\n",
            "[Impact Pack] vae encoded in 0.2s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:02<00:00,  3.78it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 9.57 seconds\n",
            "100% 32/32 [00:05<00:00,  5.73it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(266.60596), np.float32(349.13333))) | crop region (512, 512) x 1.920437216758728 -> (983, 983)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.94it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.63 seconds\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(175.6808), np.float32(247.6382))) | crop region (512, 512) x 2.000215530395508 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            " 90% 9/10 [00:03<00:00,  2.66it/s]got prompt\n",
            "100% 10/10 [00:03<00:00,  2.80it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.91 seconds\n",
            "100% 32/32 [00:05<00:00,  5.74it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(230.40813), np.float32(242.56897))) | crop region (512, 512) x 2.0012974739074707 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.77it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.94 seconds\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(261.90002), np.float32(358.0432))) | crop region (512, 512) x 1.9549444913864136 -> (1000, 1000)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.82it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.86 seconds\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(160.03021), np.float32(244.7994))) | crop region (480, 512) x 2.0001108646392822 -> (960, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.94it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.68 seconds\n",
            "100% 32/32 [00:05<00:00,  5.75it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(212.735), np.float32(288.79547))) | crop region (512, 512) x 2.000415802001953 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.78it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.93 seconds\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(185.42303), np.float32(201.31845))) | crop region (512, 512) x 2.0010783672332764 -> (1024, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  2.78it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.95 seconds\n",
            "100% 32/32 [00:05<00:00,  5.67it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(136.2436), np.float32(187.20764))) | crop region (408, 512) x 2.0000860691070557 -> (816, 1024)\n",
            "[Impact Pack] vae encoded in 0.2s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:02<00:00,  3.54it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 9.96 seconds\n",
            "100% 32/32 [00:05<00:00,  5.72it/s]\n",
            "\n",
            "0: 640x640 1 face, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(146.1548), np.float32(182.29764))) | crop region (438, 512) x 2.0006749629974365 -> (876, 1024)\n",
            "[Impact Pack] vae encoded in 0.3s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:03<00:00,  3.30it/s]\n",
            "[Impact Pack] vae decoded in 0.4s\n",
            "Prompt executed in 10.18 seconds\n",
            "got prompt\n",
            "100% 32/32 [00:05<00:00,  5.67it/s]\n",
            "\n",
            "0: 640x640 1 face, 11.8ms\n",
            "Speed: 2.8ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Detailer: segment upscale for ((np.float32(134.87486), np.float32(170.3687))) | crop region (404, 511) x 2.004754066467285 -> (809, 1024)\n",
            "[Impact Pack] vae encoded in 0.2s\n",
            "Requested to load SDXL\n",
            "100% 10/10 [00:02<00:00,  3.65it/s]\n",
            "[Impact Pack] vae decoded in 0.3s\n",
            "Prompt executed in 9.87 seconds\n",
            "got prompt\n",
            "invalid prompt: {'type': 'prompt_no_outputs', 'message': 'Prompt has no outputs', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* CLIPLoader 83:30:\n",
            "  - Value not in list: clip_name: 'qwen_3_4b.safetensors' not in []\n",
            "* UNETLoader 83:28:\n",
            "  - Value not in list: unet_name: 'z_image_turbo_bf16.safetensors' not in []\n",
            "* VAELoader 83:29:\n",
            "  - Value not in list: vae_name: 'ae.safetensors' not in ['diffusion_pytorch_model.safetensors', 'pixel_space']\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Failed to validate prompt for output 60:\n",
            "* CLIPLoader 83:30:\n",
            "  - Value not in list: clip_name: 'qwen_3_4b.safetensors' not in []\n",
            "* UNETLoader 83:28:\n",
            "  - Value not in list: unet_name: 'z_image_turbo_bf16.safetensors' not in []\n",
            "Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "Using pytorch attention in VAE\n",
            "Using pytorch attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "gguf qtypes: Q6_K (29), F32 (113), Q4_K (169)\n",
            "Dequantizing token_embd.weight to prevent runtime OOM.\n",
            "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "Requested to load OvisTEModel_\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely; 21147.17 MB usable, 1400.50 MB loaded, full load: True\n",
            "gguf qtypes: F32 (245), BF16 (28), Q5_K (46), Q6_K (30), Q4_K (104)\n",
            "model weight dtype torch.bfloat16, manual cast: None\n",
            "model_type FLOW\n",
            "Requested to load Lumina2\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "loaded completely; 19744.67 MB usable, 4880.47 MB loaded, full load: True\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 36.49 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.04 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.08 seconds\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n",
            "got prompt\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "!!! Exception during processing !!! Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ComfyUI/execution.py\", line 518, in execute\n",
            "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 329, in get_output_data\n",
            "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb, v3_data=v3_data)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/execution.py\", line 303, in _async_map_node_over_list\n",
            "    await process_inputs(input_dict, i)\n",
            "  File \"/content/ComfyUI/execution.py\", line 291, in process_inputs\n",
            "    result = f(**inputs)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1542, in sample\n",
            "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/nodes.py\", line 1509, in common_ksampler\n",
            "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/sample.py\", line 60, in sample\n",
            "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1178, in sample\n",
            "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1068, in sample\n",
            "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 1050, in sample\n",
            "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 994, in outer_sample\n",
            "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed, latent_shapes=latent_shapes)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 980, in inner_sample\n",
            "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 752, in sample\n",
            "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1432, in sample_res_multistep\n",
            "    return res_multistep(model, x, sigmas, extra_args=extra_args, callback=callback, disable=disable, s_noise=s_noise, noise_sampler=noise_sampler, eta=0., cfg_pp=False)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/k_diffusion/sampling.py\", line 1390, in res_multistep\n",
            "    denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 401, in __call__\n",
            "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 953, in __call__\n",
            "    return self.outer_predict_noise(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 960, in outer_predict_noise\n",
            "    ).execute(x, timestep, model_options, seed)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 963, in predict_noise\n",
            "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 381, in sampling_function\n",
            "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
            "    return _calc_cond_batch_outer(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 214, in _calc_cond_batch_outer\n",
            "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/samplers.py\", line 326, in _calc_cond_batch\n",
            "    output = model.apply_model(input_x, timestep_, **c).chunk(batch_chunks)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 163, in apply_model\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/model_base.py\", line 205, in _apply_model\n",
            "    model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 600, in forward\n",
            "    return comfy.patcher_extension.WrapperExecutor.new_class_executor(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/patcher_extension.py\", line 112, in execute\n",
            "    return self.original(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ldm/lumina/model.py\", line 622, in _forward\n",
            "    cap_feats = self.cap_embedder(cap_feats)  # (N, L, D)  # todo check if able to batchify w.o. redundant compute\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 287, in forward\n",
            "    return self.forward_comfy_cast_weights(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/ops.py\", line 279, in forward_comfy_cast_weights\n",
            "    x = comfy.rmsnorm.rms_norm(input, weight, self.eps)  # TODO: switch to commented out line when old torch is deprecated\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ComfyUI/comfy/rmsnorm.py\", line 21, in rms_norm\n",
            "    return rms_norm_torch(x, weight.shape, weight=comfy.model_management.cast_to(weight, dtype=x.dtype, device=x.device), eps=eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\", line 2920, in rms_norm\n",
            "    return torch.rms_norm(input, normalized_shape, weight, eps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Given normalized_shape=[2560], expected input with shape [*, 2560], but got input of size[1, 256, 2048]\n",
            "\n",
            "Prompt executed in 0.02 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}